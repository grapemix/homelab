# This PV doesn't work for some reason and it seems we can use volusync to backup without messing with the root path
#---
#apiVersion: v1
#kind: PersistentVolume
#metadata:
#  name: fast-cephfs-family-media
#spec:
#  accessModes:
#    - ReadWriteMany
#  capacity:
#    storage: 2Ti
#  storageClassName: "fast-ceph-filesystem"
#  csi:
#    driver: rook-ceph.cephfs.csi.ceph.com
#    nodeStageSecretRef:
#      # node stage secret name
#      name: rook-csi-cephfs-node-user
#      # node stage secret namespace where above secret is created
#      namespace: rook-ceph
#    volumeAttributes:
#      # Required options from storageclass parameters need to be added in volumeAttributes
#      "clusterID": "rook-ceph"
#      "fsName": "fast-ceph-filesystem"
#      "pool": "fast-data0"
#      "staticVolume": "true"
#      "rootPath": /volumes/_nogroup/family/media/ac00d91e-aff1-4f44-b70e-adfcb6e0f4aa
#    # volumeHandle can be anything, need not to be same
#    # as PV name or volume name. keeping same for brevity
#    volumeHandle: fast-cephfs-family-media-pvc
#  persistentVolumeReclaimPolicy: Retain
#  volumeMode: Filesystem
#---
#apiVersion: v1
#kind: PersistentVolumeClaim
#metadata:
#  name: fast-cephfs-family-media-pvc
#  namespace: media
#  labels:
#    backup: "false"
#spec:
#  accessModes:
#    - ReadWriteMany
#  storageClassName: "fast-ceph-filesystem"
#  resources:
#    requests:
#      storage: 2Ti
#  volumeMode: Filesystem
#  # volumeName should be same as PV name
#  #volumeName: fast-cephfs-family-media
---
#apiVersion: batch/v1
#kind: Job
#metadata:
#  name: k8s-janitor
#  namespace: kube-system
#  labels:
#    app: k8s-janitor
#spec:
#  template:
#    spec:
#      serviceAccountName: k8s-janitor-role
#      restartPolicy: Never
#      containers:
#        - name: k8s-janitor
#          imagePullPolicy: Always
#          image: bitnami/kubectl
#          command: ["/bin/bash", "-c"]
#          args:
#            - export userID=$(kubectl get secret rook-csi-cephfs-node -n rook-ceph -o=jsonpath="{.data.adminID}" | base64 -d);
#              export userKey=$(kubectl get secret rook-csi-cephfs-node -n rook-ceph -o=jsonpath="{.data.adminKey}" | base64 -d);
#              kubectl create secret generic rook-csi-cephfs-node-user -n rook-ceph --from-literal=userID=$userID --from-literal=userKey=$userKey;
#  backoffLimit: 4
#---
#kind: ClusterRoleBinding
#apiVersion: rbac.authorization.k8s.io/v1
#metadata:
#  name: k8s-janitor-role
#subjects:
#  - kind: ServiceAccount
#    name: k8s-janitor-role
#    namespace: kube-system
#roleRef:
#  kind: ClusterRole
#  name: cluster-admin
#  apiGroup: rbac.authorization.k8s.io
#---
#apiVersion: v1
#kind: ServiceAccount
#metadata:
#  name: k8s-janitor-role
#  namespace: kube-system
#---
